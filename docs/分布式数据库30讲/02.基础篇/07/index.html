<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-architect2/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-architect2";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>07 | 数据复制：为什么有时候Paxos不是最佳选择？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/分布式数据库30讲/02.基础篇/07" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect2/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>架构师<ul><li><a href="/blog-architect2/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect2/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-architect2/分布式协议与算法实战">分布式协议与算法实战</a></li><li><a href="/blog-architect2/分布式技术原理与算法解析">分布式技术原理与算法解析</a></li><li><a aria-current="page" class="active" href="/blog-architect2/分布式数据库30讲">分布式数据库30讲</a></li><li><a href="/blog-architect2/分布式金融架构课">分布式金融架构课</a></li><li><a href="/blog-architect2/李智慧高并发架构实战课">李智慧高并发架构实战课</a></li><li><a href="/blog-architect2/深入浅出分布式技术原理">深入浅出分布式技术原理</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect2/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>架构师<ul><li><a href="/blog-architect2/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect2/消息队列进阶">消息队列进阶</a></li><li><a href="/blog-architect2/分布式协议与算法实战">分布式协议与算法实战</a></li><li><a href="/blog-architect2/分布式技术原理与算法解析">分布式技术原理与算法解析</a></li><li><a aria-current="page" class="active" href="/blog-architect2/分布式数据库30讲">分布式数据库30讲</a></li><li><a href="/blog-architect2/分布式金融架构课">分布式金融架构课</a></li><li><a href="/blog-architect2/李智慧高并发架构实战课">李智慧高并发架构实战课</a></li><li><a href="/blog-architect2/深入浅出分布式技术原理">深入浅出分布式技术原理</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-architect2/分布式数据库30讲">分布式数据库30讲</a></li><li><a href="/blog-architect2/分布式数据库30讲/01.开篇词">01.开篇词</a><ul><li><a href="/blog-architect2/分布式数据库30讲/01.开篇词/01"><span>开篇词｜为什么要学习分布式数据库？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-architect2/分布式数据库30讲/02.基础篇">02.基础篇</a><ul><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/01"><span>01｜什么是分布式数据库？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/02"><span>02｜强一致性：那么多数据一致性模型，究竟有啥不一样？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/03"><span>03｜强一致性：别再用BASE做借口，来看看什么是真正的事务一致性</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/04"><span>04 | 架构风格：NewSQL和PGXC到底有啥不一样？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/05"><span>05 | 全局时钟：物理时钟和逻辑时钟你Pick谁？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/06"><span>06 | 分片机制：为什么说Range是更好的分片策略？</span></a></li><li><a aria-current="page" class="active" href="/blog-architect2/分布式数据库30讲/02.基础篇/07"><span>07 | 数据复制：为什么有时候Paxos不是最佳选择？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/02.基础篇/08"><span>08 | 基础篇大串讲：重难点回顾+思考题答疑+知识全景图</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇">03.开发篇</a><ul><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/01"><span>09｜原子性：2PC还是原子性协议的王者吗？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/02"><span>10 | 原子性：如何打破事务高延迟的魔咒？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/03"><span>11｜隔离性：读写冲突时，快照是最好的办法吗？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/04"><span>12 | 隔离性：看不见的读写冲突，要怎么处理？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/05"><span>13 | 隔离性：为什么使用乐观协议的分布式数据库越来越少?</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/06"><span>14 | 隔离性：实现悲观协议，除了锁还有别的办法吗？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/07"><span>15 | 分布式事务串讲：重难点回顾+思考题答疑+知识全景图</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/08"><span>16 | 为什么不建议你使用存储过程？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/09"><span>17 | 为什么不建议你使用自增主键？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/10"><span>18 | HTAP是不是赢者通吃的游戏？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/11"><span>19 | 查询性能优化：计算与存储分离架构下有哪些优化思路？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/12"><span>20 | 关联查询：如何提升多表Join能力？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/13"><span>21 | 查询执行引擎：如何让聚合计算加速？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/14"><span>22｜RUM猜想：想要读写快还是存储省？又是三选二</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/03.开发篇/15"><span>23 | 数据库查询串讲：重难点回顾+思考题答疑+知识全景图</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇">04.实践篇</a><ul><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/01"><span>24 | 全球化部署：如何打造近在咫尺且永不宕机的数据库？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/02"><span>25 | 容灾与备份：如何设计逃生通道保证业务连续性？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/03"><span>26 | 容器化：分布式数据库要不要上云，你想好了吗？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/04"><span>27 | 产品测试：除了性能跑分，还能测个啥？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/05"><span>28 | 选型案例：银行是怎么选择分布式数据库的？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/06"><span>29 | 产品图鉴：哪些分布式数据库值得看？</span></a></li><li><a href="/blog-architect2/分布式数据库30讲/04.实践篇/07"><span>30 | 实践篇大串讲：重难点回顾+思考题答疑+知识全景图</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/05.结束语">05.结束语</a><ul><li><a href="/blog-architect2/分布式数据库30讲/05.结束语/01"><span>结束语 | 享受职业带给你的快乐</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/06.测试题">06.测试题</a><ul><li><a href="/blog-architect2/分布式数据库30讲/06.测试题/01"><span>结课测试｜这些分布式数据库的问题，你都掌握了吗？</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/07.用户故事">07.用户故事</a><ul><li><a href="/blog-architect2/分布式数据库30讲/07.用户故事/01"><span>用户故事 | 李兆龙：博观而约取，厚积而薄发</span></a></li></ul></li><li><a href="/blog-architect2/分布式数据库30讲/summary">分布式数据库30讲</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="分片元数据的存储" data-depth="2"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#分片元数据的存储"><span>分片元数据的存储</span></a></li><li title="静态分片" data-depth="3"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#静态分片"><span>静态分片</span></a></li><li title="TiDB：无服务状态" data-depth="3"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#tidb无服务状态"><span>TiDB：无服务状态</span></a></li><li title="CockroachDB：去中心化" data-depth="3"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#cockroachdb去中心化"><span>CockroachDB：去中心化</span></a></li><li title="复制效率" data-depth="2"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#复制效率"><span>复制效率</span></a></li><li title="Raft的性能缺陷" data-depth="3"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#raft的性能缺陷"><span>Raft的性能缺陷</span></a></li><li title="Raft的性能优化方法（TiDB）" data-depth="3"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#raft的性能优化方法tidb"><span>Raft的性能优化方法（TiDB）</span></a></li><li title="小结" data-depth="2"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#小结"><span>小结</span></a></li><li title="思考题" data-depth="2"><a href="/blog-architect2/分布式数据库30讲/02.基础篇/07#思考题"><span>思考题</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="07--数据复制为什么有时候paxos不是最佳选择"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#07--数据复制为什么有时候paxos不是最佳选择"><span class="icon icon-link"></span></a>07 | 数据复制：为什么有时候Paxos不是最佳选择？</h1><p>你好，我是王磊，你也可以叫我Ivan。今天，我们要学习的是数据复制。</p><p>数据复制是一个老生常谈的话题了，典型的算法就是Paxos和Raft。只要你接触过分布式，就不会对它们感到陌生。经过从业者这些年的探索和科普，网上关于Paxos和Raft算法的高质量文章也是一搜一大把了。</p><p>所以，今天这一讲我不打算全面展开数据复制的方方面面，而是会聚焦在与分布式数据库相关的，比较重要也比较有意思的两个知识点上，这就是分片元数据的存储和数据复制的效率。</p><h2 id="分片元数据的存储"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#分片元数据的存储"><span class="icon icon-link"></span></a>分片元数据的存储</h2><p>我们知道，在任何一个分布式存储系统中，收到客户端请求后，承担路由功能的节点首先要访问分片元数据（简称元数据），确定分片对应的节点，然后才能访问真正的数据。这里说的元数据，一般会包括分片的数据范围、数据量、读写流量和分片副本处于哪些物理节点，以及副本状态等信息。</p><p>从存储的角度看，元数据也是数据，但特别之处在于每一个请求都要访问它，所以元数据的存储很容易成为整个系统的性能瓶颈和高可靠性的短板。如果系统支持动态分片，那么分片要自动地分拆、合并，还会在节点间来回移动。这样，元数据就处在不断变化中，又带来了多副本一致性（Consensus）的问题。</p><p>下面，让我们看看，不同的产品具体是如何存储元数据的。</p><h3 id="静态分片"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#静态分片"><span class="icon icon-link"></span></a>静态分片</h3><p>最简单的情况是静态分片。我们可以忽略元数据变动的问题，只要把元数据复制多份放在对应的工作节点上就可以了，这样同时兼顾了性能和高可靠。TBase大致就是这个思路，直接将元数据存储在协调节点上。即使协调节点是工作节点，随着集群规模扩展，会导致元数据副本过多，但由于哈希分片基本上就是静态分片，也就不用考虑多副本一致性的问题。</p><p>但如果要更新分片信息，这种方式显然不适合，因为副本数量过多，数据同步的代价太大了。所以对于动态分片，通常是不会在有工作负载的节点上存放元数据的。</p><p>那要怎么设计呢？有一个凭直觉就能想到的答案，那就是专门给元数据搞一个小规模的集群，用Paxos协议复制数据。这样保证了高可靠，数据同步的成本也比较低。</p><p>TiDB大致就是这个思路，但具体的实现方式会更巧妙一些。</p><h3 id="tidb无服务状态"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#tidb无服务状态"><span class="icon icon-link"></span></a>TiDB：无服务状态</h3><p>在TiDB架构中，TiKV节点是实际存储分片数据的节点，而元数据则由Placement Driver节点管理。Placement Driver这个名称来自Spanner中对应节点角色，简称为PD。</p><p>在PD与TiKV的通讯过程中，PD完全是被动的一方。TiKV节点定期主动向PD报送心跳，分片的元数据信息也就随着心跳一起报送，而PD会将分片调度指令放在心跳的返回信息中。等到TiKV下次报送心跳时，PD就能了解到调度的执行情况。</p><p>由于每次TiKV的心跳中包含了全量的分片元数据，PD甚至可以不落盘任何分片元数据，完全做成一个无状态服务。这样的好处是，PD宕机后选举出的新主根本不用处理与旧主的状态衔接，在一个心跳周期后就可以工作了。当然，在具体实现上，PD仍然会做部分信息的持久化，这可以认为是一种缓存。</p><p>我将这个通讯过程画了下来，希望帮助你理解。</p><p><img src="/blog-architect2/static/httpsstatic001geekbangorgresourceimage9461946f37b234790208a6643b5703e65d61.86876fcd.jpg" alt=""/></p><p>三个TiKV节点每次上报心跳时，由主副本（Leader）提供该分片的元数据，这样PD可以获得全量且没有冗余的信息。</p><p>虽然无状态服务有很大的优势，但PD仍然是一个单点，也就是说这个方案还是一个中心化的设计思路，可能存在性能方面的问题。</p><p>有没有完全“去中心化”的设计呢？当然是有的。接下来，我们就看看P2P架构的CockroachDB是怎么解决这个问题的。</p><h3 id="cockroachdb去中心化"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#cockroachdb去中心化"><span class="icon icon-link"></span></a>CockroachDB：去中心化</h3><p>CockroachDB的解决方案是使用Gossip协议。你是不是想问，为什么不用Paxos协议呢？</p><p>这是因为Paxos协议本质上是一种广播机制，也就是由一个中心节点向其他节点发送消息。当节点数量较多时，通讯成本就很高。</p><p>CockroachDB采用了P2P架构，每个节点都要保存完整的元数据，这样节点规模就非常大，当然也就不适用广播机制。而Gossip协议的原理是谣言传播机制，每一次谣言都在几个人的小范围内传播，但最终会成为众人皆知的谣言。这种方式达成的数据一致性是 “最终一致性”，即执行数据更新操作后，经过一定的时间，集群内各个节点所存储的数据最终会达成一致。</p><p>看到这，你可能有点晕。我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/272104">第2讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>就说过分布式数据库是强一致性的，现在搞了个最终一致性的元数据，能行吗？</p><p>这里我先告诉你结论，<strong>CockroachDB真的是基于“最终一致性”的元数据实现了强一致性的分布式数据库</strong>。我画了一张图，我们一起走下这个过程。</p><p><img src="/blog-architect2/static/httpsstatic001geekbangorgresourceimage3a233afa38b9a29e2ecfa17f6b809c1e2123.099ee362.jpg" alt=""/></p><ol><li>节点A接到客户端的SQL请求，要查询数据表T1的记录，根据主键范围确定记录可能在分片R1上，而本地元数据显示R1存储在节点B上。</li><li>节点A向节点B发送请求。很不幸，节点A的元数据已经过时，R1已经重新分配到节点C。</li><li>此时节点B会回复给节点A一个非常重要的信息，R1存储在节点C。</li><li>节点A得到该信息后，向节点C再次发起查询请求，这次运气很好R1确实在节点C。</li><li>节点A收到节点C返回的R1。</li><li>节点A向客户端返回R1上的记录，同时会更新本地元数据。</li></ol><p>可以看到，CockroachDB在寻址过程中会不断地更新分片元数据，促成各节点元数据达成一致。</p><p>看完TiDB和CockroachDB的设计，我们可以做个小结了。复制协议的选择和数据副本数量有很大关系：如果副本少，参与节点少，可以采用广播方式，也就是Paxos、Raft等协议；如果副本多，节点多，那就更适合采用Gossip协议。</p><h2 id="复制效率"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#复制效率"><span class="icon icon-link"></span></a>复制效率</h2><p>说完了元数据的存储，我们再看看今天的第二个知识点，也就是数据复制效率的问题，具体来说就是Raft与Paxos在效率上的差异，以及Raft的一些优化手段。在分布式数据库中，采用Paxos协议的比较少，知名产品就只有OceanBase，所以下面的差异分析我们会基于Raft展开。</p><h3 id="raft的性能缺陷"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#raft的性能缺陷"><span class="icon icon-link"></span></a>Raft的性能缺陷</h3><p>我们可以在网上看到很多比较Paxos和Raft的文章，它们都会提到在复制效率上Raft会差一些，主要原因就是Raft必须“顺序投票”，不允许日志中出现空洞。在我看来，顺序投票确实是影响Raft算法复制效率的一个关键因素。</p><p>接下来，我们就分析一下为什么“顺序投票”对性能会有这么大的影响。</p><p>我们先看一个完整的Raft日志复制过程：</p><ol><li>Leader 收到客户端的请求。</li><li>Leader 将请求内容（即Log Entry）追加（Append）到本地的Log。</li><li>Leader 将Log Entry 发送给其他的 Follower。</li><li>Leader 等待 Follower 的结果，如果大多数节点提交了这个 Log，那么这个Log Entry就是Committed Entry，Leader就可以将它应用（Apply）到本地的状态机。</li><li>Leader 返回客户端提交成功。</li><li>Leader 继续处理下一次请求。</li></ol><p>以上是单个事务的运行情况。那么，当多事务并行操作时，又是什么样子的呢？我画了张图来演示这个过程。</p><p><img src="/blog-architect2/static/httpsstatic001geekbangorgresourceimagec42bc46f44da1ae27ffe6545c3d00964ba2b.8a8ba5e2.jpg" alt=""/></p><p>我们设定这个Raft组由5个节点组成，T1到T5是先后发生的5个事务操作，被发送到这个Raft组。</p><p>事务T1的操作是将X置为1，5个节点都Append成功，Leader节点Apply到本地状态机，并返回客户端提交成功。事务T2执行时，虽然有一个Follower没有响应，但仍然得到了大多数节点的成功响应，所以也返回客户端提交成功。</p><p>现在，轮到T3事务执行，没有得到超过半数的响应，这时Leader必须等待一个明确的失败信号，比如通讯超时，才能结束这次操作。因为有顺序投票的规则，T3会阻塞后续事务的进行。T4事务被阻塞是合理的，因为它和T3操作的是同一个数据项，但是T5要操作的数据项与T3无关，也被阻塞，显然这不是最优的并发控制策略。</p><p>同样的情况也会发生在Follower节点上，第一个Follower节点可能由于网络原因没有收到T2事务的日志，即使它先收到T3的日志，也不会执行Append操作，因为这样会使日志出现空洞。</p><p>Raft的顺序投票是一种设计上的权衡，虽然性能有些影响，但是节点间日志比对会非常简单。在两个节点上，只要找到一条日志是一致的，那么在这条日志之前的所有日志就都是一致的。这使得选举出的Leader与Follower同步数据非常便捷，开放Follower读操作也更加容易。要知道，我说的可是保证一致性的Follower读操作，它可以有效分流读操作的访问压力。这一点我们在24讲再详细介绍。</p><h3 id="raft的性能优化方法tidb"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#raft的性能优化方法tidb"><span class="icon icon-link"></span></a>Raft的性能优化方法（TiDB）</h3><p>当然，在真正的工程实现中，Raft主副本也不是傻傻地挨个处理请求，还是有一些优化手段的。TiDB的官方文档对Raft优化说得比较完整，我们这里引用过来，着重介绍下它的四个优化点。</p><ol><li>**批操作（Batch）。**Leader 缓存多个客户端请求，然后将这一批日志批量发送给 Follower。Batch的好处是减少的通讯成本。</li><li>**流水线（Pipeline）。**Leader本地增加一个变量（称为NextIndex），每次发送一个Batch后，更新NextIndex记录下一个Batch的位置，然后不等待Follower返回，马上发送下一个Batch。如果网络出现问题，Leader重新调整NextIndex，再次发送Batch。当然，这个优化策略的前提是网络基本稳定。</li><li>**并行追加日志（Append Log Parallelly）。**Leader将Batch发送给Follower的同时，并发执行本地的Append操作。因为Append是磁盘操作，开销相对较大，而标准流程中Follower与Leader的Append是先后执行的，当然耗时更长。改为并行就可以减少部分开销。当然，这时Committed Entry的判断规则也要调整。在并行操作下，即使Leader没有Append成功，只要有半数以上的Follower节点Append成功，那就依然可以视为一个Committed Entry，Entry可以被Apply。</li><li>**异步应用日志（Asynchronous Apply）。**Apply并不是提交成功的必要条件，任何处于Committed状态的Log Entry都确保是不会丢失的。Apply仅仅是为了保证状态能够在下次被正确地读取到，但多数情况下，提交的数据不会马上就被读取。因此，Apply是可以转为异步执行的，同时读操作配合改造。</li></ol><p>其实，Raft算法的这四项优化并不是TiDB独有的，CockroachDB和一些Raft库也做了类似的优化。比如，SOFA-JRaft也实现了Batch和Pipeline优化。</p><p>不知道你有没有听说过etcd，它是最早的、生产级的Raft协议开源实现，TiDB和CockroachDB都借鉴了它的设计。甚至可以说，它们选择Raft就是因为etcd提供了可靠的工程实现，而Paxos则没有同样可靠的工程实现。既然是开源，为啥不直接用呢？因为etcd是单Raft组，写入性能受限。所以，TiDB和CockroachDB都改造成多个Raft组，这个设计被称为Multi Raft，所有采用Raft协议的分布式数据库都是Multi Raft。这种设计，可以让多组并行，一定程度上规避了Raft的性能缺陷。</p><p>同时，Raft组的大小，也就是分片的大小也很重要，越小的分片，事务阻塞的概率就越低。TiDB的默认分片大小是96M，CockroachDB的分片不超过512M。那么，TiDB的分片更小，就是更好的设计吗？也未必，因为分片过小又会增加扫描操作的成本，这又是另一个权衡点了。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#小结"><span class="icon icon-link"></span></a>小结</h2><p>好了，今天的内容就到这里。我们一起回顾下这节课的重点。</p><ol><li>分片元数据的存储是分布式数据库的关键设计，要满足性能和高可靠两方面的要求。静态分片相对简单，可以直接通过多副本分散部署的方式实现。</li><li>动态分片，满足高可靠的同时还要考虑元数据的多副本一致性，必须选择合适的复制协议。如果搭建独立的、小规模元数据集群，则可以使用Paxos或Raft等协议，传播特点是广播。如果元数据存在工作节点上，数量较多则可以考虑Gossip协议，传播特点是谣言传播。虽然Gossip是最终一致性，但通过一些寻址过程中的巧妙设计，也可以满足分布式数据的强一致性要求。</li><li>Paxos和Raft是广泛使用的复制协议，也称为共识算法，都是通过投票方式动态选主，可以保证高可靠和多副本的一致性。Raft算法有“顺序投票”的约束，可能出现不必要的阻塞，带来额外的损耗，性能略差于Paxos。但是，etcd提供了优秀的工程实现，促进了Raft更广泛的使用，而etcd的出现又有Raft算法易于理解的内因。</li><li>分布式数据库产品都对Raft做了一定的优化，另外采用Multi Raft设计实现多组并行，再通过控制分片大小，降低事务阻塞概率，提升整体性能。</li></ol><p>讲了这么多，回到我们最开始的问题，为什么有时候Paxos不是最佳选择呢？一是架构设计方面的原因，看参与复制的节点规模，规模太大就不适合采用Paxos，同样也不适用其他的共识算法。二是工程实现方面的原因，在适用共识算法的场景下，选择Raft还是Paxos呢？因为Paxos没有一个高质量的开源实现，而Raft则有etcd这个不错的工程实现，所以Raft得到了更广泛的使用。这里的深层原因还是Paxos算法本身过于复杂，直到现在，实现Raft协议的开源项目也要比Paoxs更多、更稳定。</p><p>有关分片元数据的存储，在我看来，TiDB和CockroachDB的处理方式都很优雅，但是TiDB的方案仍然建立在PD这个中心点上，对集群的整体扩展性，对于主副本跨机房、跨地域部署，有一定的局限性。</p><p>关于Raft的优化方法，大的思路就是并行和异步化，其实这也是整个分布式系统中常常采用的方法，在第10讲原子协议的优化中我们还会看到类似的案例。</p><p><img src="/blog-architect2/static/httpsstatic001geekbangorgresourceimage1a6e1a8c2e11b0072edd80c3bd3e5f4dca6e.d898f96e.jpg" alt=""/></p><h2 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-architect2/分布式数据库30讲/02.基础篇/07#思考题"><span class="icon icon-link"></span></a>思考题</h2><p>最后是今天的思考题时间。我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/271373">第1讲<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>就提到过分布式数据库具备海量存储能力，那么你猜，这个海量有上限吗？或者说，你觉得分布式数据库的存储容量会受到哪些因素的制约呢？欢迎你在评论区留言和我一起讨论，我会在答疑篇回复这个问题。</p><p>你是不是也经常听到身边的朋友讨论数据复制的相关问题呢，而且得出的结论有可能是错的？如果有的话，希望你能把今天这一讲分享给他/她，我们一起来正确地理解分布式数据库的数据复制是怎么一回事。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/分布式数据库30讲/02.基础篇/07.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/29 14:38:21</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-architect2/umi.e65758f7.js"></script>
  </body>
</html>
